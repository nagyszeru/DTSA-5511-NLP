{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Brief description of the problem and data**","metadata":{}},{"cell_type":"markdown","source":"This Kaggle competition is about classifying texts taken from Twitter using Natural Language Processing (NLP) to classify which are about real disasters and which are not. \n\nThe complexity of the task is demonstrated using the sample Tweet provided by the competition: \"LOOK AT THE NIGHT SKY LAST NIGHT IT WAS ABLAZE\" where the author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away but it is less clear to a machine that it is not referencing a real disaster.\n\nThe dataset consists of 10,000 tweets that were hand classified.","metadata":{}},{"cell_type":"markdown","source":"# **Load Libraries**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nimport os\nimport random\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\n#from functools import reduce\n#from nltk.stem import PorterStemmer, WordNetLemmatizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/nlp-getting-started/train.csv')\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/nlp-getting-started/test.csv')\ntest_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From a high level look at the datasets it is observed:\n\n* The training set contains 7,613 entries while the testing dataset contains 3,263 entries\n* Both datasets contain 4 columns: ID, Keyword, Location, Text\n* The training dataset contains 1 additional column which we will be predicting for the test dataset: Target\n\nWe will evaluate the fields further below.\n","metadata":{}},{"cell_type":"code","source":"train_data['target'].value_counts().to_frame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.groupby(['target'])['target'].count().plot(kind='bar', color = 'blue', title='Target Distribution')\nplt.xlabel('Target')\nplt.ylabel('Count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['keyword'].value_counts()[:10].plot(kind='barh', color='blue')\nplt.title(\"Keywords - Top 10\")\nplt.xlabel(\"Count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['location'].value_counts()[:10].plot(kind='barh', color='blue')\nplt.title(\"Location - Top 10\")\nplt.xlabel(\"Count\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From the above analysis of the training dataset, we can see approximately 60% of the Tweets reference a non-disaster (target=0) versus a disaster (target=1).\n* The keywords field contains a word that represents the overall text.\n* The location field contains a geographical location from which the text originated, in some cases a country name while in others a city location.  \n* We can consider cleaning up the keyword and location for empty value or standardization yet they will not directly be used in the NLP model below so will defer doing so within the scope of this project.\n* Below, we will examine the primary field for our analysis which will be the 'text' derived from the Tweets.","metadata":{}},{"cell_type":"code","source":"text_length = train_data[train_data['target']==1]['text'].str.split().map(lambda x: len(x))\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\nfig.suptitle('WORDS IN A TWEET')\nax1.hist(text_length, color='red', edgecolor='black')\nax1.set_title('Tweets Disaster')\nax1.set_xlabel('# Words')\nax1.set_ylabel('Frequency')\ntext_length = train_data[train_data['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(text_length,color='blue', edgecolor='black')\nax2.set_title('Tweets Non-Disaster')\nax2.set_xlabel('# Words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we have a histogram of the average number of words in each text for both disaster and non-disaster related Tweets.\nIn both cases, the average number of words tends to be approximately 15 with more variance from the average for disaster versus non-disaster tweets.","metadata":{}},{"cell_type":"code","source":"positive_cases = \"\".join(train_data[train_data['target'] == 0]['text'].values)\nnegative_cases = \"\".join(train_data[train_data['target'] == 1]['text'].values)\n\nfig, axs = plt.subplots(2, 1, figsize=(20, 8))\n\nwc1 = WordCloud(background_color='white').generate(positive_cases)\nwc2 = WordCloud(background_color='white').generate(negative_cases)\n\naxs[0].imshow(wc1, interpolation='bilinear')\naxs[0].set_title('Positive')\naxs[1].imshow(wc2, interpolation='bilinear')\naxs[1].set_title('Negative')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above word cloud shows the most frequent words for each of our target categories.  While some trends start appearing, the data overall seems 'messy' with an opportunity to clean it up for greater insight and accuracy.  Below we will clean the data by applying lower case and removing:\n\n* Punctation\n* Common stopwords  \n* Words less than 4 letters\n* Non-alphabet characters","metadata":{}},{"cell_type":"code","source":"#remove punctuation\ndef remove_punctuation(x):\n    return x.translate(str.maketrans('', '', string.punctuation))\n\n#remove stopwords\ndef remove_stopwords(x):\n    return ' '.join([i for i in x.split() if i not in wordcloud.STOPWORDS])\n\n#remove words less than 4 letters\ndef remove_less_than(x):\n    return ' '.join([i for i in x.split() if len(i) > 3])\n\n#remove words with non-alphabet characters\ndef remove_non_alphabet(x):\n    return ' '.join([i for i in x.split() if i.isalpha()])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['clean_text'] = train_data['text'].apply(lambda x: x.lower())\ntrain_data['clean_text'] = train_data['clean_text'].apply(remove_less_than)\ntrain_data['clean_text'] = train_data['clean_text'].apply(remove_non_alphabet)\ntrain_data['clean_text'] = train_data['clean_text'].apply(remove_stopwords)\ntrain_data['clean_text'] = train_data['clean_text'].apply(remove_punctuation)\nprint('done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_cases = \"\".join(train_data[train_data['target'] == 0]['clean_text'].values)\nnegative_cases = \"\".join(train_data[train_data['target'] == 1]['clean_text'].values)\n\nfig, axs = plt.subplots(2, 1, figsize=(20, 8))\n\nwc1 = WordCloud(background_color='white').generate(positive_cases)\nwc2 = WordCloud(background_color='white').generate(negative_cases)\n\naxs[0].imshow(wc1, interpolation='bilinear')\naxs[0].set_title('Positive')\naxs[1].imshow(wc2, interpolation='bilinear')\naxs[1].set_title('Negative')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the result of the text cleanup, the above word clouds provide greater insight to the words driving the target characterisation.   The clarity of the cleansed text will be helpful in the below model.  While there are additional opportunities to address mis-spellings and abbreviations within the text further, the current cleansed text will suffice within the scope of this week's assignment.","metadata":{}},{"cell_type":"markdown","source":"# **Model Architecture**","metadata":{}},{"cell_type":"markdown","source":"We will build a long short term memory network (LSTM) model which is a variety of recurrent neural network discussed during the class lecture.  The LSTM architecture provides a short-term memory for RNN that can last thousands of timesteps, thus \"long short-term memory\". The intuition behind the LSTM architecture is to create an additional module in a neural network that effectively learns which information might be needed later on in a sequence and when that information is no longer needed - making it a great architecture for natural language processing where we need the network to learn grammatical dependencies.","metadata":{}},{"cell_type":"markdown","source":"First, we will tokenize each text sentence. Tokenization will break down the sentences into individual words in order to create a matrix of the relationship between those words.  In totality, this is referred to as a corpus.","metadata":{}},{"cell_type":"code","source":"max_features=3000\ntokenizer=Tokenizer(num_words=max_features,split=' ')\ntokenizer.fit_on_texts(train_data['clean_text'].values)\nx = tokenizer.texts_to_sequences(train_data['clean_text'].values)\nx = pad_sequences(x)\nx.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.\n# reference: https://www.tensorflow.org/xla\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"embed_dim = 32\nlstm_out = 32\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_dim,input_length = x.shape[1]))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.4))\nmodel.add(Dense(1,activation='sigmoid'))\nadam = optimizers.Adam(learning_rate=0.002)\nmodel.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results and Analysis**","metadata":{}},{"cell_type":"markdown","source":"To evaluate the results, we will split the training data 80% for training the model and 20% to validate the results as shown below:","metadata":{}},{"cell_type":"code","source":"y = train_data['target']\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 777)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, epochs = 10, batch_size=32, validation_data=(x_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(x_test).round()\nprint(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confuse = confusion_matrix(y_test,y_pred)\nplt.figure(figsize=(4, 4))\nsns.heatmap(confuse, annot=True, fmt='g', cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix visualizes and summarizes the performance of the classification:\n\n* Precision, the ratio between the true positives and all the positives, checks the accuracy of the postive class. Out of all the tweets the the model predicted  would be disaster related 75% actual are.\n* Recall, the ratio between the number of true positives and number of false negatives, is a measure of the model correctly identifying true positives. Out of all the tweets that were related to disasters, the model predicted this outcome for 81%.\n* The f1-score of 78% tells us the model did a pretty good job of predicting if the text was related to true disaster.\n* Overall accuracy is 74%","metadata":{}},{"cell_type":"markdown","source":"We can adjust the model parameters to attempt to improve the results.   Let's try to increase the learning rate and reduce the drop rate:","metadata":{}},{"cell_type":"code","source":"embed_dim = 32\nlstm_out = 32\nmodel2 = Sequential()\nmodel2.add(Embedding(max_features, embed_dim,input_length = x.shape[1]))\nmodel2.add(Dropout(0.1))\nmodel2.add(LSTM(lstm_out, dropout=0.1, recurrent_dropout=0.2))\nmodel2.add(Dense(1,activation='sigmoid'))\nadam = optimizers.Adam(learning_rate=0.10)\nmodel2.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.fit(x_train, y_train, epochs = 10, batch_size=32, validation_data=(x_test, y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['clean_text'] = test_data['text'].apply(lambda x: x.lower())\ntest_data['clean_text'] = test_data['clean_text'].apply(remove_less_than)\ntest_data['clean_text'] = test_data['clean_text'].apply(remove_non_alphabet)\ntest_data['clean_text'] = test_data['clean_text'].apply(remove_stopwords)\ntest_data['clean_text'] = test_data['clean_text'].apply(remove_punctuation)\n\nl =50\nmax_features=5000\ntokenizer=Tokenizer(num_words=max_features,split=' ')\ntokenizer.fit_on_texts(train_data['clean_text'].values)\nx = tokenizer.texts_to_sequences(train_data['clean_text'].values)\nx = pad_sequences(x, maxlen =l)\n\ntokenizer.fit_on_texts(train_data['clean_text'].values)\ntest_token = tokenizer.texts_to_sequences(test_data['clean_text'].values)\ntest_token = pad_sequences(test_token, maxlen =l)\n\nprint('done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_dim = 100\nlstm_out = 100\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_dim,input_length = x.shape[1]))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\nadam = optimizers.Adam(learning_rate=2e-3)\nmodel.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\nmodel.fit(x,y, epochs = 10,validation_split = 0.2 ,batch_size=32) #callbacks=[es_callback], ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_hat = model.predict(test_token).round()\nsubmission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nsubmission['target'] = np.round(y_hat).astype('int')\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.groupby(['target'])['target'].count().plot(kind='bar', color = 'blue', title='Target - Test Predictions Distribution')\nplt.xlabel('Target')\nplt.ylabel('Count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"adfadfadfadf","metadata":{}}]}